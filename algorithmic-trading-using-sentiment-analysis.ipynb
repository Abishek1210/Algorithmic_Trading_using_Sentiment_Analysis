{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INSTALLING PACKAGES","metadata":{"id":"bvip-rvvkOER"}},{"cell_type":"markdown","source":"We install all the necessary packages to build the model","metadata":{"id":"V0hFS7_gL4vI"}},{"cell_type":"code","source":"!pip install glom","metadata":{"id":"miV4CH3luPiu","outputId":"434327eb-9379-4bac-adf6-a641e891e06e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install yfinance","metadata":{"id":"BoVQ3PoLIMwv","outputId":"b29829ba-caba-4c48-817a-ac5cd8f6d55a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install newspaper3k","metadata":{"id":"JM3353n0k70n","outputId":"48797d3e-b358-46e7-8c81-75281c431922"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bs4","metadata":{"id":"wBZLc9bVGXiT","outputId":"613b5c60-e2a5-4ff4-bc91-af375dec0fab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"id":"ecH8UdWyVNsW","outputId":"98ad40db-9b08-42b3-aa7b-bfdd2160a4a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tweepy","metadata":{"id":"V-B7p25ar2X4","scrolled":true,"outputId":"df4c4c53-e79d-4052-b1ce-fa7289fd2615"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install htmldate","metadata":{"id":"9I5kBpo-r2X8","outputId":"867db27b-a5f5-4894-ea41-ed54089d7cca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"id":"QaaJf7Uq4y6V","outputId":"d9d44f34-2d4c-443e-d69c-5764ee76a0d1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"scrolled":true,"id":"KW7TTJGyw1Ov","outputId":"2e00e958-29f6-417f-cb19-4848708171a9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers[torch]==4.3","metadata":{"scrolled":true,"id":"eeZ1iuP1w1Ov","outputId":"bce87370-4abc-4be6-b6b4-a857c2c49437"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# IMPORTING PACKAGES","metadata":{"id":"GmGD6X_Esws0"}},{"cell_type":"markdown","source":"Import packages for performing data extraction, cleaning, visulaization, and modelling","metadata":{"id":"ZXabj6GKMEVe"}},{"cell_type":"code","source":"import tweepy, json","metadata":{"id":"x9VI76m3IMwt","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glom import glom","metadata":{"id":"Q5y4CQF6Nwsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"HFDrvLGoNxha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"l2n5LKwINx4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"id":"UE0NmQnCNyDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime, timedelta","metadata":{"id":"7vsslWqxNyNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yfinance as yf","metadata":{"id":"SJLrFW3rNyVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup","metadata":{"id":"2yUdMXMiNzsb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests","metadata":{"id":"YInoEMOjN0AR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"id":"9Lt-WUAuN0Rf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from newspaper import *","metadata":{"id":"nC_RdfgAN0h5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from htmldate import find_date","metadata":{"id":"V94wgPaPN0xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords","metadata":{"id":"EIztEc2kxIBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import PegasusTokenizer, PegasusForConditionalGeneration","metadata":{"id":"IHpK6_WDOQd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification","metadata":{"id":"lwolAGOfpxR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"id":"Bzq4p92GORO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"Psj9sGyulxqx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# COLLECTING TWITTER DATA","metadata":{"id":"v6ohsQYZIMwt"}},{"cell_type":"markdown","source":"Getting developer access from twitter to extract historical tweets for upto 7 days\n\nNOTE: The keys below are private and are to be kept confidential and not be misused without the owner's authorization","metadata":{"id":"tAAQFFT8MR6o"}},{"cell_type":"code","source":"api_key = \"D3a1PVON8wECC8ZB781LXEY0I\"\napi_secret_key = \"lrrXjpTn0P2Rj1R1lH3cVn1KUA4xrTZyrRzb9Jfgwx1bKPC5Y2\"\naccess_token = \"1319681101-suDjXaeuUGiCMVoQ3ZHmwIv84CNkXbkvuSE39JK\"\naccess_token_secret = \"IvLRZh7i2PaxmXr4riVb7QZoLBOzqS3MJfDEEq9nX9oYU\"","metadata":{"id":"bdW76J5tIMwt","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auth = tweepy.OAuthHandler(api_key,api_secret_key)\nauth.set_access_token(access_token,access_token_secret)\napi = tweepy.API(auth)","metadata":{"id":"MHS1ponzIY7v","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tweets(ticker_list, count):\n  tweets = pd.DataFrame()\n\n  for i in range(len(ticker_list)):\n    results = api.search(q=ticker_list[i], lang='en', count=count)\n    results = pd.DataFrame(results)\n    temp = pd.DataFrame()\n\n    temp['Timestamp'] = results[0].apply(lambda row: glom(row, 'created_at'))\n    temp['Title'] = results[0].apply(lambda row: glom(row, 'text'))\n    temp['Ticker'] = ticker_list[i]\n    temp['Tweet ID'] = results[0].apply(lambda row: glom(row, 'id'))\n    temp['User ID'] = results[0].apply(lambda row: glom(row, 'user.id'))\n    temp['Name'] = results[0].apply(lambda row: glom(row, \"user.screen_name\"))\n    temp['Followers'] = results[0].apply(lambda row: glom(row, 'user.followers_count'))\n    temp['Location'] = results[0].apply(lambda row: glom(row, 'user.location'))\n    tweets = tweets.append(temp)\n    tweets.drop_duplicates(inplace=True)\n  return tweets","metadata":{"id":"azFgmJna6CR-","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ticker list includes the name of all stocks under NIFTY Bank\n\nTweets containing any of these keywords are extracted","metadata":{"id":"LbY9p5oHNBlF"}},{"cell_type":"code","source":"ticker_list = [\"NIFTY BANK\", 'SBIN', 'IDBI', 'AXISBANK', 'HDFCBANK', 'KOTAKBANK', 'PNB', 'ICICIBANK', 'BARODA', 'CANARA', 'INDUSIND', 'BANKINDIA', 'UNION']\ncount = 1000\n\ntweets = get_tweets(ticker_list=ticker_list, count=count)","metadata":{"id":"9eh9uAp_IMwu","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.head()","metadata":{"id":"gu7ZhncB-1p2","scrolled":true,"outputId":"ef6e81c3-124a-44bc-8fb2-61ed8d7a8ef9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def firstandlastdate(dataframe):\n  first = np.min(dataframe['Timestamp'])\n  last = np.max(dataframe['Timestamp'])\n  return first, last","metadata":{"id":"Oy3Q755f-19B","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_tw, last_tw = firstandlastdate(tweets)\n\nprint('Starting: '+str(first_tw) +'\\n' +'Ending: '+str(last_tw))","metadata":{"id":"ZNUJcwef_cSU","scrolled":true,"outputId":"3e1c32e1-dbcf-480c-88fe-81a6bdb20066"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.info()","metadata":{"id":"y6fFu89gonfc","outputId":"077e1205-cc28-4ae6-d4ca-a58b4b4d0918"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXTRACTING NEWS","metadata":{"id":"8aZxbRsQ6fLQ"}},{"cell_type":"markdown","source":"Functions are created to crawl webpages to get URLs, filter them, and feed it through the data extraction algorithm to get news data","metadata":{"id":"68GPgh4ONYGo"}},{"cell_type":"code","source":"def search_for_stocks_news_urls(ticker, url_list):\n    for url in url_list:\n        search_url = url.format(ticker)\n        r = requests.get(search_url)\n        soup = BeautifulSoup(r.text, 'html.parser')\n        atags = soup.find_all('a')\n        hrefs = [tag['href'] if tag.has_attr('href') else '' for tag in atags]\n    return hrefs","metadata":{"id":"3UQ-RD45GKbA","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strip_unwanted_urls(urls, exclude_list):\n    val = []\n    for url in urls: \n        if 'https://' in url and not any(exclude_word in url for exclude_word in exclude_list):\n            res = re.findall(r'(https?://\\S+)', url)[0].split('&')[0]\n            val.append(res)\n    return list(set(val))","metadata":{"id":"74oz1ELnzxmo","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Newspaper3k package is used exclusively to find the publish date of each article extracted","metadata":{"id":"8tSbZZr0N2cH"}},{"cell_type":"code","source":"def publish_date(URLs):\n    publishdate = []\n    for url in URLs:\n        try:\n            publishdate.append(str(find_date(url)))\n        except:\n            publishdate.append(\"None\")\n            pass\n    return publishdate","metadata":{"id":"JZlw3Anur2Yf","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_news_data(ticker_list, cleaned_urls):\n    articles_info = []\n    \n    for ticker in ticker_list:\n        links = cleaned_urls[ticker]\n    \n        for i in links:\n            article_dict = {}\n            article = Article(i)\n            article.download()\n\n            article_dict[\"link\"] = i\n            article_dict[\"Ticker\"] = ticker\n\n            try:\n                article.parse()\n                article_dict[\"Text\"] = article.text\n                article_dict[\"Title\"] = article.title\n                article.nlp()\n\n            except ArticleException:\n                article_dict[\"Text\"] = np.nan\n                article_dict[\"Title\"] = np.nan\n\n            articles_info.append(article_dict)\n\n    news_data = pd.DataFrame(articles_info)\n    return news_data","metadata":{"id":"YSThOktdGp9N","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticker_list = [\"NIFTY BANK\", 'SBIN', 'IDBI', 'AXISBANK', 'HDFCBANK', 'KOTAKBANK', 'PNB', 'ICICIBANK', 'BARODA', 'CANARA', 'INDUSIND', 'BANKINDIA', 'UNION']\n\nurl_list = [\"https://www.google.com/search?q={}&tbm=nws\"] \n\nraw_urls = {ticker:search_for_stocks_news_urls(ticker=ticker, url_list=url_list) for ticker in ticker_list}","metadata":{"id":"VP6YBb7dGr5S","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"links = []\nfor ticker in ticker_list:\n    print('Number of URLs in '+ticker + ': '+str(len(raw_urls[ticker])))\n    for link in raw_urls[ticker]:\n        links.append(link)\nprint('Total number of raw URLs: '+str(len(links)))","metadata":{"id":"vz6dcuZGr2Yh","scrolled":true,"outputId":"6013af4d-3db0-45ac-988b-4dea89d31dfd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exclude_list = ['maps', 'policies', 'preferences', 'accounts', 'support']\n\ncleaned_urls = {ticker:strip_unwanted_urls(raw_urls[ticker], exclude_list) for ticker in ticker_list}","metadata":{"id":"GvUNcs85rHll","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"links = []\nfor ticker in ticker_list:\n    print('Number of URLs in '+ticker + ': '+str(len(cleaned_urls[ticker])))\n    for link in cleaned_urls[ticker]:\n        links.append(link)\nprint('Total number of cleaned URLs: '+str(len(links)))","metadata":{"id":"eNtOrXiXz5Sj","scrolled":true,"outputId":"5cc10ba7-28c5-4546-ba54-2bc612fe3825"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles_publishdate = {ticker:publish_date(cleaned_urls[ticker]) for ticker in ticker_list}\narticles_publishdate","metadata":{"id":"UR_bZ8wWAl1M","scrolled":true,"outputId":"056564b1-2749-49cb-9259-0cc68dcbf0a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = []\nfor ticker in ticker_list:\n    count = 0\n    for value in articles_publishdate[ticker]:\n        if value != \"None\":\n            count = count + 1\n    print('Number of URLs in '+ticker + ' with dateofpub: '+str(count))\n    for date in articles_publishdate[ticker]:\n        dates.append(link)  ","metadata":{"id":"kFkUMU8N2fPI","scrolled":true,"outputId":"40762385-ba5f-4748-f156-717304adc72a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = []\nfor ticker in ticker_list:\n    print('Number of URLs in '+ticker + ' with dateofpub: '+str(len(articles_publishdate[ticker])))\n    for date in articles_publishdate[ticker]:\n        dates.append(link)","metadata":{"id":"Xdy5S2XD0F-l","scrolled":true,"outputId":"7b62cc19-7071-425e-b928-ea7756ae8c30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data = get_news_data(ticker_list=ticker_list, cleaned_urls=cleaned_urls)","metadata":{"scrolled":true,"id":"_w5_eQ-mw1O2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = []\nfor ticker in ticker_list:\n    for l in articles_publishdate[ticker]:\n        dates.append(l)\n\nnews_data['Timestamp'] = dates","metadata":{"scrolled":true,"id":"P5OGq-ySw1O2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Articles without publish date are removed and are converted to datetime datatype so that it uniform with the stock data","metadata":{"id":"mXcZo1ifOP0E"}},{"cell_type":"code","source":"news_data = news_data[news_data['Timestamp'] != 'None']","metadata":{"scrolled":true,"id":"I7G-Wmkuw1O2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data['Timestamp'] = news_data['Timestamp'].apply(lambda date: datetime(int(date[:4]), int(date[5:7]), int(date[8:])))","metadata":{"id":"8AemEn8P8egm","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timestamp_adjuster(timestamp, start, delta):\n\n    if timestamp >= datetime(timestamp.year,timestamp.month,timestamp.day,9,15) and timestamp <= datetime(timestamp.year,timestamp.month,timestamp.day,15,15):\n        timestamp = start + math.ceil((timestamp - start) / delta) * delta\n\n    elif timestamp > datetime(timestamp.year,timestamp.month,timestamp.day,15,15) and timestamp < datetime(timestamp.year,timestamp.month,timestamp.day)+timedelta(days=1):\n        timestamp = datetime(timestamp.year,timestamp.month,timestamp.day,9,15) + timedelta(days=1)\n  \n    else:\n        timestamp = datetime(timestamp.year,timestamp.month,timestamp.day,9,15)\n  \n    return timestamp","metadata":{"id":"xoZRIp-Cr2Yl","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data['Timestamp'] = news_data['Timestamp'].apply(lambda x: datetime.strptime(x.strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S'))\n\nnews_data['Timestamp'] = news_data['Timestamp'].apply(lambda x: timestamp_adjuster(x, start=datetime(2020,1,1,0,15), delta=timedelta(hours=1)))","metadata":{"id":"Sy4ZzJ41o8od","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data.dropna(subset=['Text'], axis=0, inplace=True)","metadata":{"id":"5a3_T8DkQPzH","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data['Text'] = news_data['Text'].apply(lambda x: str(x))","metadata":{"id":"fF06dbqHTYkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data.index = range(0, len(news_data))","metadata":{"id":"aYeuBYJaQ4Ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data.head()","metadata":{"id":"Q_pY14jVw1O3","outputId":"d9888292-14ed-4907-98a4-194df110b7d6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_ne, last_ne = firstandlastdate(news_data)\n\nprint('Starting: '+str(first_ne) +'\\n' +'Ending: '+str(last_ne))","metadata":{"id":"dQBsaXIrnAqd","outputId":"15dff879-d1ad-4bfb-cf9f-5fc2049e01c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n# GETTING STOCKS DATA","metadata":{"id":"6sqkUG3ckgOt"}},{"cell_type":"markdown","source":"Stock data with a resolution of 1 hour is extracted from Yahoo Finance using appropriate tickers for the period where news data and tweets are available","metadata":{"id":"KoPyXvBJOo36"}},{"cell_type":"code","source":"def get_stocksdata(ticker_list, start, end, period, resolution):\n    stocks_data = pd.DataFrame()\n    for i in range(len(ticker_list)):\n        temp = yf.download(tickers=[ticker_list[i-1]], start=start, end=end, auto_adjust=True, period=period, interval=resolution)\n        temp['Timestamp'] = temp.index\n        temp['Symbol'] = ticker_list[i-1]\n        stocks_data = stocks_data.append(temp)\n    return stocks_data","metadata":{"id":"4uphikKVmL2f","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_ticker_list = [\"^NSEBANK\", 'SBIN.NS', 'IDBI.NS', 'AXISBANK.NS', 'HDFCBANK.NS', 'KOTAKBANK.NS', 'PNB.NS', 'ICICIBANK.NS', 'BANKBARODA.NS', 'CANBK.NS', 'INDUSINDBK.NS', 'BANKINDIA.NS', 'UNIONBANK.NS'] \nstart = min(first_tw, first_ne)\nend = min(last_tw, last_ne)\nperiod = '1d'\nresolution = '1h'\n\nstocks_data = get_stocksdata(ticker_list=stocks_ticker_list, start=start, end=end, period=period, resolution=resolution)","metadata":{"id":"AzLd3yk_f9Q2","scrolled":true,"outputId":"0c314edd-4c96-4427-930c-ce5d3e46d209"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data.index = range(1, len(stocks_data)+1)","metadata":{"id":"OtkSJXl7RrgB","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data['Date'] = stocks_data['Timestamp'].apply(lambda x: x.date)\n\nstocks_data['Time'] = stocks_data['Timestamp'].apply(lambda x: x.time)\n\nstocks_data['Timestamp'] = stocks_data['Timestamp'].apply(lambda x: datetime.strptime(x.strftime('%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S'))","metadata":{"id":"D4rA5OwYTsml","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_symbol_map = {'NIFTY BANK':\"^NSEBANK\", 'SBIN':'SBIN.NS', 'IDBI':'IDBI.NS', 'AXISBANK':'AXISBANK.NS', 'HDFCBANK':'HDFCBANK.NS', \n                     'KOTAKBANK':'KOTAKBANK.NS', 'PNB':'PNB.NS', 'ICICIBANK':'ICICIBANK.NS', 'BARODA':'BANKBARODA.NS', \n                     'CANARA':'CANBK.NS', 'INDUSIND':'INDUSINDBK.NS', 'BANKINDIA':'BANKINDIA.NS', 'UNION':'UNIONBANK.NS'}\nsymbol_stocks_map = {k:v for v,k in stocks_symbol_map.items()}\n\nstocks_data['Ticker'] = stocks_data['Symbol'].map(symbol_stocks_map)","metadata":{"id":"wqy-vXkFWAf4","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data.head()","metadata":{"scrolled":true,"id":"YkwuRBBhw1O6","outputId":"ae7e416d-a15e-404d-cf3a-cf9664dcf03e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data = stocks_data[['Open', 'Volume', 'Ticker', 'Timestamp']]","metadata":{"scrolled":true,"id":"qYv0_cAOw1O7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1, len(stocks_data['Timestamp'])+1):\n  temp = stocks_data['Timestamp'][i]\n  stocks_data['Timestamp'][i] = datetime(temp.year, temp.month, temp.day, temp.hour, temp.minute, temp.second)","metadata":{"id":"sdRJ31lsOf82","outputId":"6d44af9e-a8d1-4f29-f2dc-25b44586bd23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data[stocks_data['Ticker'] == 'NIFTY BANK']","metadata":{"id":"dY3pXFs2IIBA","outputId":"9742cc7a-f48e-4d4e-b8cb-f42314efb41a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n# SUMMARIZING TEXT AND PERFORMING SENTIMENT ANALYSIS","metadata":{"id":"7h8vGUlJBg9z"}},{"cell_type":"code","source":"tweets['Timestamp'] = tweets['Timestamp'].apply(lambda x: timestamp_adjuster(timestamp=x, start=datetime(2020,1,1,0,15), delta=timedelta(hours=1)))","metadata":{"id":"b_Q91csaADgl","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets = tweets[['Ticker', 'Title', 'Timestamp']]","metadata":{"scrolled":true,"id":"jRKJWFQjw1O6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.columns = ['Ticker', 'Text Summary', 'Timestamp']","metadata":{"id":"mAWJJe_IfvB-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"News data is summarized using a pre-trained model","metadata":{"id":"vBS_VX-BPX9H"}},{"cell_type":"code","source":"summarizer = pipeline(\"summarization\")","metadata":{"id":"C8wRnDNfCWDT","outputId":"eb071e93-67a9-4d2b-c2e6-6acc9094bb81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Text_Summary = []\nfor i in range(0, len(news_data['Text'])):\n  summary = summarizer(news_data['Text'][i][:512], max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n  Text_Summary.append(summary)","metadata":{"id":"9pMtO_KU5m8B","outputId":"b3a317e1-4fb7-4fdd-dec4-baee72780b58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_data['Text Summary'] = Text_Summary","metadata":{"id":"iGIJRG23SFjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets = news_data[['Ticker', 'Text Summary', 'Timestamp']].append(tweets)","metadata":{"id":"GHJRH-GY529w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.index = range(0, len(news_and_tweets['Text Summary']))","metadata":{"id":"F3Cgsqt3m6C3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.head()","metadata":{"id":"VbnPem0InYOz","outputId":"51b9ee96-1411-4bc9-fc26-f194e5bf15d2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Irrelavant and insignificant words are removed and fed into FINBERT model for performing Sentiment Analysis\n\nFINBERT is a pre-trained NLP model with weights for a corpus of words from the English language with more relevance to financial context","metadata":{"id":"XSmIuf2NPmAm"}},{"cell_type":"code","source":"stop = stopwords.words('english')\nstop[:5]","metadata":{"id":"jujJeALcw8J_","outputId":"e2cb2067-6806-4a69-b5aa-2e10eaaf96f7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets['Text Summary'] = news_and_tweets['Text Summary'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop]))","metadata":{"id":"DqxjAtLYz2oH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.head()","metadata":{"id":"3ZRdEwrd6zsL","outputId":"3bf120e2-e025-4000-f198-8b96c89dd10c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n\nclassifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)","metadata":{"id":"e2eoDQZNoSlg","outputId":"7a7d6045-b34c-4186-bd33-610a68e72636"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets = news_and_tweets.assign(sentiment = lambda x: x['Text Summary'].apply(lambda s: classifier(s))).assign(label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score'])))","metadata":{"id":"2CmSwiuVobNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.head()","metadata":{"id":"bsaAHfUIscbG","outputId":"bfdca7c5-b8f6-49e7-86b7-2fae87319f23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, len(news_and_tweets['Timestamp'])):\n  temp = news_and_tweets['Timestamp'][i]\n  news_and_tweets['Timestamp'][i] = datetime(temp.year, temp.month, temp.day, temp.hour, temp.minute, temp.second)","metadata":{"id":"kix3xBBRLI9G","outputId":"ed5936c8-9b76-479b-a3aa-6059bbd8b77e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.drop('sentiment', axis=1, inplace=True)","metadata":{"id":"OPnrSZAIunhw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.columns = ['Ticker', 'Text Summary', 'Timestamp', 'Sentiment', 'Sentiment Score']","metadata":{"id":"Mn4S3jOE9Wxq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sentiment is represented in trading terms based on the polarity scores\n\nArticles with neutral sentiments or low polarity scores are treated as neutral","metadata":{"id":"jcqDRd2UQbQ1"}},{"cell_type":"code","source":"for i in range(0, len(news_and_tweets['Sentiment'])):\n  if news_and_tweets['Sentiment'][i] == 'positive' and news_and_tweets['Sentiment Score'][i] >= 0.6:\n    news_and_tweets['Sentiment'][i] = 'Buy'\n  elif news_and_tweets['Sentiment'][i] == 'negative' and news_and_tweets['Sentiment Score'][i] >= 0.6:\n    news_and_tweets['Sentiment'][i] = 'Sell'\n  else:\n    news_and_tweets['Sentiment'][i] = 'None'","metadata":{"id":"s1svD1g64DIb","outputId":"8da96031-71d9-4354-f7c5-fdd1868c8a0f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maximum budget per transaction is limited to Rs.10000 and the cost of transaction regresses with lower sentiment polarity scores\n\nAll these figures are arbitary","metadata":{"id":"bmlBmrvjQ3W7"}},{"cell_type":"code","source":"budget_per_share = 10000\nnews_and_tweets['Quantity'] = np.zeros(len(news_and_tweets['Ticker']))\n\nfor i in range(0, len(news_and_tweets['Sentiment Score'])):\n  try:\n    tstamp = news_and_tweets.loc[i]['Timestamp']\n    tick = news_and_tweets.loc[i]['Ticker']\n    if news_and_tweets['Sentiment Score'][i] >= 0.9:\n      news_and_tweets['Quantity'][i] = round((budget_per_share) / (stocks_data[(stocks_data['Ticker'] == tick) & (stocks_data['Timestamp'] == tstamp)]['Open']))\n    elif news_and_tweets['Sentiment Score'][i] >= 0.8 and news_and_tweets['Sentiment Score'][i] < 0.9:\n      news_and_tweets['Quantity'][i] = round((budget_per_share-2000) / (stocks_data[( stocks_data['Ticker'] == tick) & (stocks_data['Timestamp'] == tstamp)]['Open']))\n    elif news_and_tweets['Sentiment Score'][i] >= 0.7 and news_and_tweets['Sentiment Score'][i] < 0.8:\n      news_and_tweets['Quantity'][i] = round((budget_per_share-4000) / (stocks_data[(stocks_data['Ticker'] == tick) & (stocks_data['Timestamp'] == tstamp)]['Open']))\n    elif news_and_tweets['Sentiment Score'][i] >= 0.6 and news_and_tweets['Sentiment Score'][i] < 0.7:\n      news_and_tweets['Quantity'][i] = round((budget_per_share-6000) / (stocks_data[(stocks_data['Ticker'] == tick) & (stocks_data['Timestamp'] == tstamp)]['Open']))\n    else:\n      news_and_tweets['Quantity'][i] = 0\n  except:\n    news_and_tweets['Quantity'][i] = 0","metadata":{"id":"XaaJjQav8gHj","outputId":"5c7540e8-26ef-496b-cdf4-0fcc60008869"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_and_tweets.head()","metadata":{"id":"oRMNHleWWymX","outputId":"a28922fa-5484-4042-fe0b-d76b0082f2ff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAPPING DATA AND AUTOMATION","metadata":{"id":"JBQ3J0OCmKIp"}},{"cell_type":"code","source":"nt = news_and_tweets\nnt['Timestamp'] = nt['Timestamp'].apply(lambda x: pd.to_datetime(x))","metadata":{"id":"5KeV4K_Znamg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"st = stocks_data\nst['Timestamp'] = st['Timestamp'].apply(lambda x: pd.to_datetime(x))","metadata":{"id":"-g8CjpA4naEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"News data and stock data are merged on timestamp and by ticker values","metadata":{"id":"7hYfizkQRa4G"}},{"cell_type":"code","source":"df = pd.merge_asof(st.sort_values('Timestamp'), nt.sort_values('Timestamp'), by='Ticker', on='Timestamp', direction='forward')","metadata":{"id":"v5nIeq3emPNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"eXPDLCyvmY4i","outputId":"0f4ee1be-e651-4440-bfae-a1aa6239db64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = df[['Timestamp', 'Open', 'Quantity', 'Ticker', 'Sentiment']]\nfor i in range(1, len(temp['Timestamp'])):\n  if temp['Ticker'][i] != 'NIFTY BANK':\n    temp['Open'][i] = temp['Open'][i-1]\n\nfig, ax = plt.subplots(figsize=(25,5))\nplt.plot(temp['Timestamp'], temp['Open'], marker='o', markersize=1)\nax.scatter(temp[(temp['Sentiment']=='Buy')]['Timestamp'], temp[(temp['Sentiment']=='Buy')]['Open'], marker='^', c='g')\nax.scatter(temp[(temp['Sentiment']=='Sell')]['Timestamp'], temp[(temp['Sentiment']=='Sell')]['Open'], marker='v', c='r')\nax.set_ylim([min(temp[temp['Ticker']=='NIFTY BANK']['Open']), max(temp[temp['Ticker']=='NIFTY BANK']['Open'])])\nax.set_xlabel('Timestamp')\nax.set_ylabel('Rupees')\nax.set_title('NIFTY BANK')","metadata":{"id":"7IVrk7gVvieB","outputId":"8bfe83f2-d4fc-4253-9eb1-a18e3bc2577c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=12, ncols=1, figsize=(25,50))\ntl = ticker_list\n\nfor t in range(0, len(tl)-1):\n  temp = df[['Timestamp', 'Open', 'Quantity', 'Ticker', 'Sentiment']]\n  for i in range(1, len(temp['Timestamp'])):\n    if temp['Ticker'][i] != tl[t]:\n      temp['Open'][i] = temp['Open'][i-1]\n\n  axes[t].plot(temp['Timestamp'], temp['Open'], c='b')\n  axes[t].scatter(temp[(temp['Sentiment']=='Buy') & (temp['Ticker']==tl[t])]['Timestamp'], temp[(temp['Sentiment']=='Buy') & (temp['Ticker']==tl[t])]['Open'], marker='^', c='g')\n  axes[t].scatter(temp[(temp['Sentiment']=='Sell') & (temp['Ticker']==tl[t])]['Timestamp'], temp[(temp['Sentiment']=='Sell') & (temp['Ticker']==tl[t])]['Open'], marker='v', c='r')\n  axes[t].set_ylim([min(temp[temp['Ticker']==tl[t]]['Open']), max(temp[temp['Ticker']==tl[t]]['Open'])])\n  axes[t].set_xlabel('Timestamp')\n  axes[t].set_ylabel('Rupees')\n  axes[t].set_title(tl[t])\n  plt.tight_layout()","metadata":{"id":"_KmBQdI5mj9R","outputId":"337e687c-8834-4e5b-f1fc-cd19e12607eb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we simulate the trading through the period to arrive at the amount invested and earned based on investor sentiments","metadata":{"id":"ya1vBJzERyhS"}},{"cell_type":"code","source":"portfolio = {ticker:0 for ticker in ticker_list}\nbank = {ticker:0 for ticker in ticker_list}\ntemp = df.dropna()\n\nfor i in range(len(temp['Timestamp'])-1):\n  n_buy = {ticker:0 for ticker in ticker_list}\n  n_sell = {ticker:0 for ticker in ticker_list}\n  if temp['Sentiment'][i] == 'Buy' and n_buy[temp['Ticker'][i]] <= 3:\n    buy_qty = temp['Quantity'][i] \n    cost_buy = buy_qty * temp['Open'][i]\n    if portfolio[temp['Ticker'][i]] * temp['Open'][i] <= 10000:\n      portfolio[temp['Ticker'][i]] += buy_qty\n      bank[temp['Ticker'][i]] -= cost_buy\n      n_buy[temp['Ticker'][i]] += 1\n      n_sell[temp['Ticker'][i]] -= 1\n  elif temp['Sentiment'][i] == 'Sell' and n_sell[temp['Ticker'][i]] <= 3:\n    sell_qty = temp['Quantity'][i] \n    cost_sell = sell_qty * temp['Open'][i]\n    if portfolio[temp['Ticker'][i]] * temp['Open'][i] <= 10000:\n      portfolio[temp['Ticker'][i]] -= sell_qty\n      bank[temp['Ticker'][i]] += cost_sell\n      n_buy[temp['Ticker'][i]] -= 1\n      n_sell[temp['Ticker'][i]] += 1 \n  else:\n    bank[temp['Ticker'][i]] += 0\n\nsum = 0\nvalue = 0\nfor ticker in {ticker:0 for ticker in ticker_list[1:]}:\n  quantity = portfolio[ticker]\n  price = round(temp[temp['Ticker'] == ticker].iloc[-1]['Open'], 2)\n  value = round(quantity * price, 2)\n  print(ticker +' : \\n' +'Quantity = ' +str(quantity) +'\\n' +'Price = ' +str(price) +'\\n' +'Value = ' +str(value) +'\\n' +'Bank = ' +str(round(bank[ticker])))\n  print('\\n')\n  sum += value\n\nbank_total = 0\nfor i in ([bank[ticker] for ticker in ticker_list[1:]]):\n  bank_total += i\n\nprint('\\n')  \nprint('Total Value (Position) of Portfolio at end: \\n' \n      +'Bank = ' +str(round(bank_total)) +'\\n'\n      +'Portfolio = ' +str(round(sum)) +'\\n'\n      +'Total = ' +str(round(bank_total + sum)))","metadata":{"id":"b5UWxInyx9mo","outputId":"cdef8279-4c19-44bc-d679-cc444ed8056a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, we automate an alternate scenario where the same amount of money is invested in the NIFTY Bank index fund at the same time instead of individual stocks","metadata":{"id":"bIWEHE3CSHDa"}},{"cell_type":"code","source":"bank = 0\ntemp = df.dropna()\nindex_qty = 0\n\nfor i in range(len(temp['Timestamp'])-1):\n  if temp['Sentiment'][i] == 'Buy':\n    buy_qty = temp['Quantity'][i] \n    cost_buy = buy_qty * temp['Open'][i]\n    index_price = temp[(temp['Ticker'] == 'NIFTY BANK') & (temp['Timestamp'] == temp['Timestamp'][i])].iloc[-1]['Open']\n    if cost_buy <= 10000:\n      index_qty += cost_buy / index_price\n      bank -= cost_buy\n  elif temp['Sentiment'][i] == 'Sell':\n    sell_qty = temp['Quantity'][i]\n    cost_sell = sell_qty * temp['Open'][i]\n    index_price = temp[(temp['Ticker'] == 'NIFTY BANK') & (temp['Timestamp'] == temp['Timestamp'][i])].iloc[-1]['Open']\n    index_qty -= cost_sell / index_price\n    bank += cost_sell\n  else:\n    bank += 0\n\nprice = temp[temp['Ticker'] == 'NIFTY BANK'].iloc[-1]['Open']\nindex_fund = index_qty * price\nprint('Bank = ' +str(round(bank)) +'\\n')\nprint('Index Quantity = ' +str(index_qty) +' Index Price = ' +str(round(price)) +' Index Fund = ' +str(round(index_fund)) +'\\n')\nprint('Total Value (Position) of NIFTY BANK fund at end = ' +str(round(bank + index_fund)))","metadata":{"id":"Mdcyh-uaDgFd","outputId":"720fa56d-3be3-4d9b-f314-b4de9f0c5a27"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is evident that the results are better when traded using the model","metadata":{"id":"w_qXUbtSScVE"}}]}